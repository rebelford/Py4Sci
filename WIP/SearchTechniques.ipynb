{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491d6673-1b8d-495c-bc02-4ec0c6d8f6a9",
   "metadata": {},
   "source": [
    "# Glob Module\n",
    "The glob module in Python is a powerful tool for file and directory pattern matching. It allows you to search for files and directories using wildcard characters, making it easy to find and manipulate multiple files at once.\n",
    "\n",
    "## Key Features of glob\n",
    "\n",
    "1. **Pattern Matching**: glob uses Unix shell-style wildcards for pattern matching[1][2].\n",
    "   - `*`: Matches any number of characters\n",
    "   - `?`: Matches any single character\n",
    "   - `[...]`: Matches any character within the brackets\n",
    "\n",
    "2. **Recursive Searching**: With Python 3.5+, you can use `**` to search recursively through directories[3].\n",
    "\n",
    "3. **Built-in Module**: glob is part of Python's standard library, so no additional installation is required[1][4].\n",
    "\n",
    "## Searching with glob\n",
    "\n",
    "To use glob for searching, you typically follow these steps:\n",
    "\n",
    "1. Import the module: `import glob`\n",
    "2. Use the `glob.glob()` function with a pattern to find matching files or directories.\n",
    "\n",
    "For example, to find all Python files in the current directory:\n",
    "\n",
    "```python\n",
    "import glob\n",
    "python_files = glob.glob('*.py')\n",
    "```\n",
    "\n",
    "## Searching in the Working Directory\n",
    "\n",
    "Yes, glob can search files in the working directory. By default, if you don't specify a path, glob searches in the current working directory[5].\n",
    "\n",
    "## Searching Jupyter Notebooks\n",
    "\n",
    "Jupyter notebooks have the `.ipynb` extension, so you can search for them using glob:\n",
    "\n",
    "```python\n",
    "jupyter_notebooks = glob.glob('*.ipynb')\n",
    "```\n",
    "\n",
    "## Searching File Contents\n",
    "\n",
    "While glob is primarily used for filename matching, it can be combined with file reading operations to search within files, including Jupyter notebooks[6]. Here's an example:\n",
    "\n",
    "```python\n",
    "import glob\n",
    "import json\n",
    "\n",
    "search_term = 'your_search_term'\n",
    "notebooks = glob.glob('*.ipynb')\n",
    "\n",
    "for notebook in notebooks:\n",
    "    with open(notebook, 'r') as f:\n",
    "        nb_content = json.load(f)\n",
    "        for cell in nb_content['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                if search_term in ''.join(cell['source']):\n",
    "                    print(f\"Found '{search_term}' in {notebook}\")\n",
    "                    break\n",
    "```\n",
    "\n",
    "This script searches for a specific term within the code cells of Jupyter notebooks in the current directory.\n",
    "\n",
    "Remember that while glob is powerful for file matching, it's not designed for complex text searching within files. For more advanced text searching, you might want to consider using regular expressions or specialized text search libraries[7].\n",
    "\n",
    "Citations:\n",
    "[1] https://www.scaler.com/topics/glob-in-python/\n",
    "[2] https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/\n",
    "[3] https://pynative.com/python-glob/\n",
    "[4] https://www.boardinfinity.com/blog/glob-in-python-2/\n",
    "[5] https://training.galaxyproject.org/training-material/topics/data-science/tutorials/python-glob/tutorial.html\n",
    "[6] https://builtin.com/software-engineering-perspectives/glob-in-python\n",
    "[7] https://favtutor.com/blogs/glob-python\n",
    "[8] https://www.youtube.com/watch?v=WHk96pueSK0\n",
    "[9] https://pythonology.eu/glob-module-file-searching-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ab8df6-863a-4c8c-ad8f-5a7d87bb9aa1",
   "metadata": {},
   "source": [
    "Yes, you can definitely create a search function to accomplish what you're looking for. The combination of glob and regular expressions is indeed a great approach for this task. Based on the search results, I can provide you with a solution that searches through all Jupyter notebooks in your sabbatical folder, including subfolders, and allows you to search for phrases in headers.\n",
    "\n",
    "Here's a Python function that does this:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        matching = [header for header in headers if search_phrase in header]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "# Example usage\n",
    "base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "search_term = \"example\"  # Replace with the phrase you want to search for\n",
    "results = search_notebooks_for_headers(base_directory, search_term)\n",
    "\n",
    "# Print results\n",
    "for notebook, headers in results.items():\n",
    "    print(f\"Notebook: {notebook}\")\n",
    "    for header in headers:\n",
    "        print(f\"  Header: {header}\")\n",
    "```\n",
    "\n",
    "This function does the following:\n",
    "\n",
    "1. It uses glob to recursively find all `.ipynb` files in the specified base directory and its subdirectories.\n",
    "2. For each notebook, it reads the content and parses it as JSON.\n",
    "3. It then searches through markdown cells for headers (lines starting with #).\n",
    "4. If the search phrase is found in a header, it adds the notebook and the matching header to the results.\n",
    "\n",
    "To use this function:\n",
    "\n",
    "1. Place this code in a Jupyter notebook in one of your folders.\n",
    "2. Replace `\"sabbat\"` with the actual path to your main sabbatical folder.\n",
    "3. Replace `\"example\"` with the phrase you want to search for in headers.\n",
    "4. Run the cell, and it will print out all notebooks and headers that contain your search phrase.\n",
    "\n",
    "This approach allows you to search for phrases in headers across all your notebooks efficiently. If you want to search in all text, not just headers, you can modify the regex pattern and remove the header-specific filtering.\n",
    "\n",
    "Citations:\n",
    "[1] https://www.youtube.com/watch?v=p_75ljGkYnM\n",
    "[2] https://builtin.com/software-engineering-perspectives/glob-in-python\n",
    "[3] https://stackoverflow.com/questions/50255553/search-jupyter-notebook-markdown-cells-from-command-line\n",
    "[4] https://discourse.jupyter.org/t/search-for-text-in-the-output-of-a-jupyter-cell/1658\n",
    "[5] https://stackoverflow.com/questions/13031989/regular-expression-usage-in-glob-glob\n",
    "[6] https://www.datacamp.com/tutorial/markdown-in-jupyter-notebook\n",
    "[7] https://www.youtube.com/watch?v=JtTEVfC1vwM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2ddca5-1c27-4bf1-9882-01f205ac6569",
   "metadata": {},
   "source": [
    "# Working Doc Header Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0abdb7-8b64-4dc6-8055-91cb206dc5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the header you would like to search for:  print\n",
      "Should the search be case sensitive? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: /home/rebelford/sabbat/2019OLCC/lecture06-molecular-similarity.ipynb\n",
      "  Header: ## 1. Fingerprint Generation\n",
      "  Header: ### 1-(2) Circular Fingerprints\n",
      "  Header: ### 1-(3) Path-Based Fingeprints\n",
      "  Header: ### 1-(4) PubChem Fingerprint\n",
      "Notebook: /home/rebelford/sabbat/2019OLCC/lecture08-machine-learning.ipynb\n",
      "  Header: ## 6. Merge activity data and fingerprint information\n",
      "Notebook: /home/rebelford/sabbat/Weiss/SciCompChemNotebooks/chapter_08/chap_08_notebook.ipynb\n",
      "  Header: ### 8.1.2 Pretty Printing\n",
      "Notebook: /home/rebelford/sabbat/Lin_Engin-Sci/bob/pp18-19_EngPy.ipynb\n",
      "  Header: # Print the names of the objects without their contents\n",
      "Notebook: /home/rebelford/sabbat/Lin_Engin-Sci/bob/ppEngPyB3_9-10.ipynb\n",
      "  Header: # Print the list of files\n",
      "  Header: # Print the list of .ipynb files\n",
      "  Header: # Print the list of .ipynb files\n",
      "Notebook: /home/rebelford/sabbat/Lin_Engin-Sci/bob/ppEngPyB4_12.ipynb\n",
      "  Header: # Print the generated arrays\n",
      "  Header: # Print the generated arrays\n",
      "Notebook: /home/rebelford/sabbat/Lin_Engin-Sci/bob/ppEngPyB2.ipynb\n",
      "  Header: # print(py_list.min())   # This would raise an AttributeError\n",
      "Notebook: /home/rebelford/sabbat/Walters_cheminformatics_tutorials-main/bob/P05SterioisomersTautomers.ipynb\n",
      "  Header: # Print the number of stereoisomers\n",
      "  Header: # Print SMILES for each stereoisomer\n",
      "  Header: # Print the number of stereoisomers\n",
      "  Header: # Print the list of stereoisomers\n",
      "  Header: # Print the number of stereoisomers\n",
      "  Header: # Print SMILES for each stereoisomer in the list\n",
      "  Header: # Print Steroisomers to Grid\n",
      "Notebook: /home/rebelford/sabbat/Walters_cheminformatics_tutorials-main/bob/P02_SMILES.ipynb\n",
      "  Header: # Print the results\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/pp_02rdkit.ipynb\n",
      "  Header: # Print information about chiral centers\n",
      "  Header: # Print the results\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/Molecular_Informatics_Midterm_Exam.ipynb\n",
      "  Header: ### Question 5: Molecular Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/5_molecular_similarity.ipynb\n",
      "  Header: ## 1. Fingerprint Generation\n",
      "  Header: ### 1-(2) Circular Fingerprints\n",
      "  Header: ### 1-(3) Path-Based Fingeprints\n",
      "  Header: ### 1-(4) PubChem Fingerprint\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/Practice_Midterm.ipynb\n",
      "  Header: ## Question 5: Molecular Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/future_weeks/Practice_Midterm_Answer_Key.ipynb\n",
      "  Header: ## Question 5: Molecular Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/Reed_Scott/molecular_informatics-main/future_weeks/5_molecular_similarity.ipynb\n",
      "  Header: ## 1. Fingerprint Generation\n",
      "  Header: ### 1-(2) Circular Fingerprints\n",
      "  Header: ### 1-(3) Path-Based Fingeprints\n",
      "  Header: ### 1-(4) PubChem Fingerprint\n",
      "Notebook: /home/rebelford/sabbat/ClassNoteBooks/pp_01_OOP_Data_Structures.ipynb\n",
      "  Header: # print(py_list.min())   # This would raise an AttributeError\n",
      "Notebook: /home/rebelford/sabbat/Hill-PythonForChemists/PerP4ChemPart3.ipynb\n",
      "  Header: # Enable LaTeX pretty printing\n",
      "Notebook: /home/rebelford/sabbat/Bob_SandBox/SearchTechniques.ipynb\n",
      "  Header: # Print results\n",
      "  Header: # Print all notebook paths\n",
      "  Header: # Print headers for a specific notebook\n",
      "  Header: # Print all results in a different format\n",
      "  Header: # Print results\n",
      "Notebook: /home/rebelford/sabbat/RDKit/Pandas_FingerPrint.ipynb\n",
      "  Header: ## Interpreting the fingerprint\n",
      "  Header: # Visualizing Hashed Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/RDKit/P_RDKitModules.ipynb\n",
      "  Header: # Generate Morgan fingerprint with bit information\n",
      "  Header: ## Interpreting the fingerprint\n",
      "  Header: # Visualizing Hashed Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/MolSSI-Python-Cheminfo/K03_molecular_similarity.ipynb\n",
      "  Header: ## Molecular Fingerprints\n",
      "  Header: ## First attempt to get the code to print index numbers\n",
      "  Header: # Generate fingerprints\n",
      "  Header: # Generate fingerprints\n",
      "  Header: # Generate fingerprints using RDKFingerprint\n",
      "  Header: # Generate Morgan fingerprints\n",
      "  Header: # Generate fingerprints using RDKFingerprint\n",
      "  Header: # Generate Morgan fingerprints and get bit info\n",
      "  Header: # Generate fingerprints using RDKFingerprint\n",
      "  Header: # Generate Morgan fingerprints and get bit info\n",
      "  Header: ## Compare RDKit and PubChem fingerprints\n",
      "Notebook: /home/rebelford/sabbat/MolSSI-Python-Cheminfo/03_molecular_similarity.ipynb\n",
      "  Header: ## Molecular Fingerprints\n",
      "Notebook: /home/rebelford/sabbat/MolSSI-Python-Cheminfo/Untitled.ipynb\n",
      "  Header: # Print key values at Ï„\n",
      "Notebook: /home/rebelford/sabbat/Air_Quality/EPA_RSIG.ipynb\n",
      "  Header: # Print dataset information\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results = search_notebooks_for_headers(base_directory, search_term)\\n\\n# Print results\\nfor notebook, headers in results.items():\\n    print(f\"Notebook: {notebook}\")\\n    for header in headers:\\n        print(f\"  Header: {header}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "###\n",
    "def search_with_toggle(base_dir):\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (yes/no): \").strip().lower() == 'yes'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "###\n",
    "# Example usage\n",
    "#base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "#search_term = \"lists\"  # Replace with the phrase you want to search for\n",
    "#search_term = input(\"Enter the header you would like to search for\")\n",
    "\n",
    "search_with_toggle(base_directory)\n",
    "\n",
    "#results = search_notebooks_for_headers(base_directory, search_term)\n",
    "'''results = search_notebooks_for_headers(base_directory, search_term)\n",
    "\n",
    "# Print results\n",
    "for notebook, headers in results.items():\n",
    "    print(f\"Notebook: {notebook}\")\n",
    "    for header in headers:\n",
    "        print(f\"  Header: {header}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc9fb5-abb6-432d-a632-19abe6e63e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f8ee6-3d2a-4097-af6e-33a8b4c44907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sabbat_path = os.path.join(os.path.expanduser('~'), 'sabbat')\n",
    "sys.path.append(sabbat_path)\n",
    "import my_fun\n",
    "\n",
    "my_fun.search_headers()\n",
    "#my_fun.rgb_to_color_name(.2,.4,.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e97a7-7fda-4024-8cc9-e9032065bc45",
   "metadata": {},
   "source": [
    "I'm thrilled to hear that it works! You're very welcome. It's great that we were able to resolve the issue and get your `search_headers` function working correctly within your `my_fun.py` module.\n",
    "\n",
    "This solution allows you to:\n",
    "1. Keep your code organized in a reusable module\n",
    "2. Easily import and use the `search_headers` function in any of your Jupyter notebooks\n",
    "3. Maintain a clean structure with imports at the top of the file\n",
    "\n",
    "Remember, you can now use this function in any notebook by importing it like this:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import os\n",
    "sabbat_path = os.path.join(os.path.expanduser('~'), 'sabbat')\n",
    "sys.path.append(sabbat_path)\n",
    "import my_fun\n",
    "\n",
    "my_fun.search_headers()\n",
    "```\n",
    "\n",
    "If you need to search in a different directory, you can also pass a custom path:\n",
    "\n",
    "```python\n",
    "my_fun.search_headers(\"/path/to/custom/directory\")\n",
    "```\n",
    "\n",
    "This modular approach will make your work more efficient and your code more maintainable as you continue with your sabbatical project. If you have any more questions or need further assistance, don't hesitate to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da7b5c-8013-4749-a95c-fa32572d8720",
   "metadata": {},
   "source": [
    "# my_fun.search.headers()\n",
    "Explain the code\n",
    "### code\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67100781-e637-4ad5-9dbb-932259af83e2",
   "metadata": {},
   "source": [
    "Certainly! I'd be happy to provide an overview of what happens when you call `my_fun.search_headers()`. Here's a high-level explanation of the process:\n",
    "\n",
    "1. The `search_headers()` function is called.\n",
    "\n",
    "2. It sets up the base directory (default is ~/sabbat) and prompts the user for:\n",
    "   - A search phrase\n",
    "   - Whether the search should be case-sensitive\n",
    "\n",
    "3. It then calls the `search_notebooks_for_headers()` function with these parameters.\n",
    "\n",
    "4. `search_notebooks_for_headers()` does the following:\n",
    "   - Uses `glob` to find all `.ipynb` files in the base directory and its subdirectories.\n",
    "   - For each notebook file:\n",
    "     - Opens the file and reads its content.\n",
    "     - Uses `json` to parse the notebook content (Jupyter notebooks are stored as JSON files).\n",
    "     - Looks for markdown cells within the notebook.\n",
    "     - Within markdown cells, it searches for headers (lines starting with #).\n",
    "     - If it finds headers matching the search phrase, it stores them.\n",
    "\n",
    "5. The function returns a dictionary of matching headers for each notebook.\n",
    "\n",
    "6. `search_headers()` then prints the results, showing each notebook path and the matching headers found.\n",
    "\n",
    "The role of JSON in this process is crucial because Jupyter notebooks are stored as JSON files. JSON (JavaScript Object Notation) is a lightweight data interchange format that's easy for humans to read and write and easy for machines to parse and generate. In a Jupyter notebook:\n",
    "\n",
    "- Each cell (code, markdown, etc.) is represented as a JSON object.\n",
    "- The entire notebook structure, including metadata, is stored in JSON format.\n",
    "\n",
    "By using `json.load()`, we're able to read and parse the notebook file, allowing us to access its structure and content programmatically. This enables us to search through the markdown cells for headers without having to manually parse the raw file content.\n",
    "\n",
    "This approach allows for efficient searching across multiple notebooks, treating each notebook as a structured document rather than just a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa50f43a-d8e0-4a29-989f-f2685e0b171b",
   "metadata": {},
   "source": [
    "I apologize for the confusion. You're right to question this, as the dictionary isn't explicitly shown in the output. Let's clarify where the dictionary is created and how you can access it.\n",
    "\n",
    "In the `search_notebooks_for_headers` function, a dictionary called `matching_headers` is created:\n",
    "\n",
    "```python\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}  # This is where the dictionary is created\n",
    "    # ... rest of the function\n",
    "```\n",
    "\n",
    "This dictionary is populated as the function searches through notebooks. The keys are the notebook file paths, and the values are lists of matching headers found in each notebook.\n",
    "\n",
    "However, in the current implementation, this dictionary is not directly accessible outside the function. The `search_headers` function calls `search_notebooks_for_headers`, gets the results, and immediately prints them without saving the dictionary for further use.\n",
    "\n",
    "To make this dictionary accessible, we can modify the `search_headers` function to return the results instead of just printing them. Here's how you can change it:\n",
    "\n",
    "```python\n",
    "def search_headers(base_directory=None):\n",
    "    if base_directory is None:\n",
    "        base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (yes/no): \").strip().lower() == 'yes'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results (you can keep this if you want)\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "\n",
    "    return results  # Return the dictionary\n",
    "\n",
    "# Usage:\n",
    "results_dict = my_fun.search_headers()\n",
    "```\n",
    "\n",
    "Now, `results_dict` will contain the dictionary with notebooks as keys and lists of matching headers as values. You can explore it like this:\n",
    "\n",
    "```python\n",
    "# Print all notebook paths\n",
    "print(results_dict.keys())\n",
    "\n",
    "# Print headers for a specific notebook\n",
    "print(results_dict['/path/to/specific/notebook.ipynb'])\n",
    "\n",
    "# Count total matches\n",
    "total_matches = sum(len(headers) for headers in results_dict.values())\n",
    "print(f\"Total matches: {total_matches}\")\n",
    "\n",
    "# Print all results in a different format\n",
    "for notebook, headers in results_dict.items():\n",
    "    print(f\"Notebook: {notebook}\")\n",
    "    print(f\"Matching headers: {headers}\\n\")\n",
    "```\n",
    "\n",
    "This modification allows you to work with the results programmatically after the search is complete, giving you more flexibility in how you use and analyze the search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2af7a5-acd8-4f98-b5b6-e26f423ca620",
   "metadata": {},
   "source": [
    "Certainly! I'll go through the code line by line and explain each step:\n",
    "\n",
    "```python\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "```\n",
    "This line defines a function that takes three parameters: the base directory to search, the phrase to search for, and whether the search should be case-sensitive (default is True).\n",
    "\n",
    "```python\n",
    "    matching_headers = {}\n",
    "```\n",
    "Initialize an empty dictionary to store the matching headers for each notebook.\n",
    "\n",
    "```python\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "```\n",
    "Use glob to find all .ipynb files in the base directory and its subdirectories. The '**' pattern allows for recursive search.\n",
    "\n",
    "```python\n",
    "    for notebook in notebook_files:\n",
    "```\n",
    "Start a loop that iterates over each notebook file found.\n",
    "\n",
    "```python\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "```\n",
    "Open the current notebook file in read mode with UTF-8 encoding.\n",
    "\n",
    "```python\n",
    "            try:\n",
    "```\n",
    "Start a try-except block to handle potential errors when reading the file.\n",
    "\n",
    "```python\n",
    "                notebook_content = json.load(f)\n",
    "```\n",
    "Parse the JSON content of the notebook file.\n",
    "\n",
    "```python\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "```\n",
    "Iterate over each cell in the notebook. If 'cells' doesn't exist, use an empty list.\n",
    "\n",
    "```python\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "```\n",
    "Check if the current cell is a markdown cell.\n",
    "\n",
    "```python\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "```\n",
    "Join all the source lines of the markdown cell into a single string.\n",
    "\n",
    "```python\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "```\n",
    "Use regex to find all lines that start with one or more '#' followed by a space, which indicates a header in markdown.\n",
    "\n",
    "```python\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "```\n",
    "Create a list of headers that contain the search phrase, respecting the case sensitivity setting.\n",
    "\n",
    "```python\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "```\n",
    "If there are matching headers, add them to the matching_headers dictionary under the current notebook's key.\n",
    "\n",
    "```python\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "```\n",
    "If there's an error parsing the JSON of a notebook, print an error message and skip that notebook.\n",
    "\n",
    "```python\n",
    "    return matching_headers\n",
    "```\n",
    "After processing all notebooks, return the dictionary of matching headers.\n",
    "\n",
    "```python\n",
    "def search_headers(base_directory=None):\n",
    "```\n",
    "Define the main search function with an optional base directory parameter.\n",
    "\n",
    "```python\n",
    "    if base_directory is None:\n",
    "        base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "```\n",
    "If no base directory is provided, use \"~/sabbat\" as the default.\n",
    "\n",
    "```python\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (yes/no): \").strip().lower() == 'yes'\n",
    "```\n",
    "Prompt the user for the search phrase and whether the search should be case-sensitive.\n",
    "\n",
    "```python\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "```\n",
    "Call the search_notebooks_for_headers function with the provided parameters.\n",
    "\n",
    "```python\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "```\n",
    "Print the results, showing each notebook path and its matching headers.\n",
    "\n",
    "This code provides a comprehensive search functionality for Jupyter notebooks, allowing users to find specific headers across multiple notebooks efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c524345-d9b2-4367-9c86-be96cf80ce5e",
   "metadata": {},
   "source": [
    "Can we look at this line here:\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "What type of variable is markdown_content? I assume it is a python list, but am confused as to how it keeps both the notebook identity and the header content.  It seems like we are bringing  everything into one list object and than operating on that.  I also do not understand ;source.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c68f7-f755-46fa-8471-f45a02a29f16",
   "metadata": {},
   "source": [
    "Excellent question! Let's break down this line and clarify some misconceptions:\n",
    "\n",
    "```python\n",
    "markdown_content = ''.join(cell.get('source', []))\n",
    "```\n",
    "\n",
    "1. `markdown_content` is actually a string, not a list. \n",
    "\n",
    "2. `cell.get('source', [])` is accessing the 'source' key of the `cell` dictionary. In Jupyter notebook JSON structure, 'source' typically contains the content of the cell as a list of strings, where each string represents a line in the cell.\n",
    "\n",
    "3. If 'source' doesn't exist in the cell dictionary, `get()` returns an empty list `[]` as a default value.\n",
    "\n",
    "4. `''.join(...)` is a string method that concatenates all the elements of an iterable (in this case, the list returned by `get()`) into a single string. The empty string `''` is used as the separator between elements.\n",
    "\n",
    "So, this line is not keeping the notebook identity or header content separately. It's simply combining all the lines of a single markdown cell into one string.\n",
    "\n",
    "The notebook identity is maintained because this operation is happening inside a loop that's processing one notebook at a time. The `notebook` variable in the outer loop keeps track of which file we're currently processing.\n",
    "\n",
    "As for headers, they haven't been identified yet at this point. The next line uses a regular expression to find headers within this `markdown_content` string:\n",
    "\n",
    "```python\n",
    "headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "```\n",
    "\n",
    "This line is what actually extracts the headers from the markdown content.\n",
    "\n",
    "So, to summarize:\n",
    "- We're not bringing everything into one list object.\n",
    "- We're processing one notebook at a time, and within each notebook, one cell at a time.\n",
    "- For each markdown cell, we're combining its content into a single string for easier processing.\n",
    "- We then search this string for headers.\n",
    "\n",
    "The structure and separation of notebooks and their contents are maintained by the nested loops and the dictionary structure of `matching_headers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74ed5b-8365-4512-b9de-de5828821e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sabbat_path = os.path.join(os.path.expanduser('~'), 'sabbat')\n",
    "sys.path.append(sabbat_path)\n",
    "import my_fun\n",
    "my_fun.search_headers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e35a69-149a-4abe-9956-66387939c92c",
   "metadata": {},
   "source": [
    "# Notebook colab search\n",
    "###\n",
    "def search_with_toggle(base_dir):\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (yes/no): \").strip().lower() == 'yes'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "###\n",
    "# Example usage\n",
    "#base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "#search_term = \"lists\"  # Replace with the phrase you want to search for\n",
    "#search_term = input(\"Enter the header you would like to search for\")\n",
    "\n",
    "search_with_toggle(base_directory)\n",
    "\n",
    "#results = search_notebooks_for_headers(base_directory, search_term)\n",
    "'''results = search_notebooks_for_headers(base_directory, search_term)\n",
    "\n",
    "# Print results\n",
    "for notebook, headers in results.items():\n",
    "    print(f\"Notebook: {notebook}\")\n",
    "    for header in headers:\n",
    "        print(f\"  Header: {header}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db556b5e-5fc1-4722-ae94-f2f078f192e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directory to be searched:  sabbat\n",
      "Enter the header you would like to search for:  heap\n",
      "Should the search be case sensitive? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching headers found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        #debugging output\n",
    "                        print(f\"Markdown content in {notebook}: {markdown_content}\")\n",
    "\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        \n",
    "                        # Debugging output: print all found headers\n",
    "                        print(f\"Found headers in {notebook}: {headers}\")\n",
    "\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "def search_with_toggle(base_directory=None):\n",
    "    if base_directory is None:\n",
    "        base_directory = input(\"Directory to be searched: \")\n",
    "    \n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive_input = input(\"Should the search be case sensitive? (y/n): \").strip().lower()\n",
    "    \n",
    "    case_sensitive = case_sensitive_input == 'y'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "\n",
    "    if results:\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "    else:\n",
    "        print(\"No matching headers found.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "search_with_toggle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd19a96-f863-4b03-83a1-184b036402d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                \n",
    "                # Debugging output: print the entire notebook content\n",
    "                print(f\"Processing notebook: {notebook}\")\n",
    "                \n",
    "                # Check cell types\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    print(f\"Cell type: {cell.get('cell_type')}\")\n",
    "                    \n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        \n",
    "                        # Debugging output: print the markdown content being processed\n",
    "                        print(f\"Markdown content in {notebook}: {markdown_content}\")\n",
    "\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "\n",
    "                        # Debugging output: print all found headers\n",
    "                        print(f\"Found headers in {notebook}: {headers}\")\n",
    "\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f34b8a6-5da2-4e8b-adc9-1f5b7803f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the directory to be searched (default is ~/sabbat):  ~/sabbat\n",
      "Enter the header you would like to search for:  heap\n",
      "Should the search be case sensitive? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: /home/rebelford/sabbat/ClassNoteBooks/pp01_gPCHardSoftware.ipynb\n",
      "  Header: # memory heap\n",
      "  Header: # HEAP memory block\n",
      "  Header: ### **1. Variable Assignment and Heap Memory**\n",
      "  Header: # Chips HEAP integers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        \n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "def search_with_toggle():\n",
    "    # Get user input for the directory to be searched\n",
    "    directory_searched = input(\"Enter the directory to be searched (default is ~/sabbat): \") or \"~/sabbat\"\n",
    "    \n",
    "    # Expand the user directory\n",
    "    base_directory = os.path.expanduser(directory_searched)\n",
    "\n",
    "    # Get user input for search phrase and case sensitivity\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive_input = input(\"Should the search be case sensitive? (y/n): \").strip().lower()\n",
    "    \n",
    "    case_sensitive = case_sensitive_input == 'y'\n",
    "\n",
    "    # Call the search function with user inputs\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "    else:\n",
    "        print(\"No matching headers found.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "search_with_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0b9b6a-b0d1-49b9-bc43-f486fc3ef6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the directory to be searched (default is ~/sabbat):  sabbat\n",
      "Enter the header you would like to search for:  heap\n",
      "Should the search be case sensitive? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: /home/rebelford/sabbat/ClassNoteBooks/pp01_gPCHardSoftware.ipynb\n",
      "  Header: # memory heap\n",
      "  Header: # HEAP memory block\n",
      "  Header: ### **1. Variable Assignment and Heap Memory**\n",
      "  Header: # Chips HEAP integers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        \n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "def search_with_toggle():\n",
    "    # Get user input for the directory to be searched\n",
    "    directory_searched = input(\"Enter the directory to be searched (default is ~/sabbat): \") or \"~/sabbat\"\n",
    "    \n",
    "    # Expand the user directory\n",
    "    base_directory = os.path.expanduser(directory_searched)\n",
    "\n",
    "    # If the input was just 'sabbat', convert it to an absolute path\n",
    "    if os.path.basename(directory_searched) == 'sabbat' and not os.path.isabs(directory_searched):\n",
    "        base_directory = os.path.join(os.path.expanduser(\"~\"), 'sabbat')\n",
    "\n",
    "    # Get user input for search phrase and case sensitivity\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive_input = input(\"Should the search be case sensitive? (y/n): \").strip().lower()\n",
    "    \n",
    "    case_sensitive = case_sensitive_input == 'y'\n",
    "\n",
    "    # Call the search function with user inputs\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "    else:\n",
    "        print(\"No matching headers found.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "search_with_toggle()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9f71dd-14ec-407c-914e-c1e267985e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directory to be searched:  sabbat\n",
      "Enter the header you would like to search for:  heap\n",
      "Should the search be case sensitive? (y/n):  n\n",
      "Do you want to perform another search? (yes/no):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the search tool.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "def search_with_toggle(base_dir):\n",
    "    while True:\n",
    "        directory_searched= input(\"Directory to be searched: \")\n",
    "        search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "        case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "        results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "        # Print results\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "\n",
    "        another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "        if another_search != \"yes\":\n",
    "            print(\"Exiting the search tool.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "#base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "base_directory = os.path.expanduser(\"~/{directory searched}\")\n",
    "search_with_toggle(base_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c85ffc-8542-4ee6-b1e9-4b1618535c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
