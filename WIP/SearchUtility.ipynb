{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2ddca5-1c27-4bf1-9882-01f205ac6569",
   "metadata": {},
   "source": [
    "# Working Doc Header Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6fcd87-96a2-41ee-b87a-95add305cfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated: /home/rebelford/sabbat/search_results_9.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_9.html\n",
      "HTML file generated: /home/rebelford/sabbat/search_results_10.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_10.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "#\n",
    "\n",
    "def generate_html_with_links(base_dir, search_phrase, base_url=\"http://localhost:8888\", case_sensitive=True):\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "    \n",
    "    html_content = \"\"\"<html>\n",
    "    <head>\n",
    "        <title>Search Results</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Search Results</h1>\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_notebooks = set()  # To avoid duplicates\n",
    "    \n",
    "    for notebook, headers in results.items():\n",
    "        if notebook in processed_notebooks:\n",
    "            continue\n",
    "        processed_notebooks.add(notebook)\n",
    "        \n",
    "        relative_path = os.path.relpath(notebook, os.path.dirname(os.path.dirname(base_dir)))\n",
    "        sharable_link = f\"{base_url}/lab/tree/{relative_path}\"\n",
    "        html_content += f\"<h2><a href=\\\"{sharable_link}\\\">{relative_path}</a></h2>\\n\"\n",
    "        html_content += \"<ul>\\n\"\n",
    "        for header in headers:\n",
    "            html_content += f\"    <li>{header}</li>\\n\"\n",
    "        html_content += \"</ul>\\n\"\n",
    "\n",
    "    html_content += \"\"\"</body>\n",
    "    </html>\"\"\"\n",
    "\n",
    "    # Append an integer to the filename to avoid overwriting\n",
    "    counter = 1\n",
    "    output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "    while os.path.exists(output_file):\n",
    "        counter += 1\n",
    "        output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"HTML file generated: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def main(base_directory, search_term, case_sensitive=True):\n",
    "    html_file = generate_html_with_links(base_directory, search_term, case_sensitive=case_sensitive)\n",
    "    print(f\"Search results saved to: {html_file}\")\n",
    "\n",
    "# In your notebook, you can then run:\n",
    "base_directory = \"/home/rebelford/sabbat/\"\n",
    "search_term = \"heap\"\n",
    "main(base_directory, search_term)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(base_directory, search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4ffaa8-63b9-4613-9a6c-78e9ec49e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the directory to be searched (default is ~/sabbat):  ~/sabbat/Weiss\n",
      "Enter the header you would like to search for:  nmr\n",
      "Should the search be case sensitive? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: /home/rebelford/sabbat/Weiss/gdocMarkdown.ipynb\n",
      "  Header: ### 9.1.1 NMR splitting\n",
      "  Header: #  11\\. NMR\n",
      "  Header: ## 11.1 nmrglue\n",
      "Notebook: /home/rebelford/sabbat/Weiss/SciCompChemNotebooks/chapter_11/chap_11_notebook.ipynb\n",
      "  Header: # Chapter 11: Nuclear Magnetic Resonance with nmrglue and nmrsim\n",
      "  Header: ## 11.1 NMR Processing with nmrglue\n",
      "  Header: ### 11.1.1 Importing Data with nmrglue\n",
      "  Header: ## 11.2 Simulating NMR with nmrsim\n",
      "  Header: ### 11.2.4 Dynamic NMR Simulations\n",
      "Notebook: /home/rebelford/sabbat/Weiss/SciCompChemNotebooks/appendix_00/appendix_00_notebook.ipynb\n",
      "  Header: ## Simulating NMR Splitting Patterns\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        \n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "def search_with_toggle():\n",
    "    # Get user input for the directory to be searched\n",
    "    directory_searched = input(\"Enter the directory to be searched (default is ~/sabbat): \") or \"~/sabbat\"\n",
    "    \n",
    "    # Expand the user directory\n",
    "    base_directory = os.path.expanduser(directory_searched)\n",
    "\n",
    "    # If the input was just 'sabbat', convert it to an absolute path\n",
    "    if os.path.basename(directory_searched) == 'sabbat' and not os.path.isabs(directory_searched):\n",
    "        base_directory = os.path.join(os.path.expanduser(\"~\"), 'sabbat')\n",
    "\n",
    "    # Get user input for search phrase and case sensitivity\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive_input = input(\"Should the search be case sensitive? (y/n): \").strip().lower()\n",
    "    \n",
    "    case_sensitive = case_sensitive_input == 'y'\n",
    "\n",
    "    # Call the search function with user inputs\n",
    "    results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    if results:\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "    else:\n",
    "        print(\"No matching headers found.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "search_with_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9933712c-d1f1-487b-b629-0af41c88da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the directory to be searched (default is ~/sabbat):  sabbat\n",
      "Enter the header you would like to search for:  heap\n",
      "Should the search be case sensitive? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook: /home/rebelford/sabbat/ClassNoteBooks/pp01_gPCHardSoftware.ipynb\n",
      "  Header: # memory heap\n",
      "  Header: # HEAP memory block\n",
      "  Header: ### **1. Variable Assignment and Heap Memory**\n",
      "  Header: # Chips HEAP integers\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to perform another search? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the search tool.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        \n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        \n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "def search_with_toggle():\n",
    "    while True:\n",
    "        # Get user input for the directory to be searched\n",
    "        directory_searched = input(\"Enter the directory to be searched (default is ~/sabbat): \") or \"~/sabbat\"\n",
    "        \n",
    "        # Expand the user directory\n",
    "        base_directory = os.path.expanduser(directory_searched)\n",
    "    \n",
    "        # If the input was just 'sabbat', convert it to an absolute path\n",
    "        if os.path.basename(directory_searched) == 'sabbat' and not os.path.isabs(directory_searched):\n",
    "            base_directory = os.path.join(os.path.expanduser(\"~\"), 'sabbat')\n",
    "    \n",
    "        # Get user input for search phrase and case sensitivity\n",
    "        search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "        case_sensitive_input = input(\"Should the search be case sensitive? (y/n): \").strip().lower()\n",
    "        \n",
    "        case_sensitive = case_sensitive_input == 'y'\n",
    "    \n",
    "        # Call the search function with user inputs\n",
    "        results = search_notebooks_for_headers(base_directory, search_phrase, case_sensitive)\n",
    "    \n",
    "        # Print results\n",
    "        if results:\n",
    "            for notebook, headers in results.items():\n",
    "                print(f\"Notebook: {notebook}\")\n",
    "                for header in headers:\n",
    "                    print(f\"  Header: {header}\")\n",
    "        else:\n",
    "            print(\"No matching headers found.\")\n",
    "            \n",
    "        another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "        if another_search != \"yes\":\n",
    "            print(\"Exiting the search tool.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "search_with_toggle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0abdb7-8b64-4dc6-8055-91cb206dc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding toggle for second search\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "###\n",
    "def search_with_toggle(base_dir):\n",
    "    #directory_searched = input(\"Enter the directory to be searched with path starting from home directory\")\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "\n",
    "    another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "    if another_search != \"yes\":\n",
    "        print(\"Exiting the search tool.\")\n",
    "        break\n",
    "    \n",
    "###\n",
    "# Example usage\n",
    "#base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "#search_term = \"lists\"  # Replace with the phrase you want to search for\n",
    "#search_term = input(\"Enter the header you would like to search for\")\n",
    "\n",
    "search_with_toggle(base_directory)\n",
    "\n",
    "#results = search_notebooks_for_headers(base_directory, search_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2e1e0-759d-418b-a7f5-9971b70c82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "###\n",
    "def search_with_toggle(base_dir):\n",
    "    #directory_searched = input(\"Enter the directory to be searched with path starting from home directory\")\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "###\n",
    "# Example usage\n",
    "#base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "#search_term = \"lists\"  # Replace with the phrase you want to search for\n",
    "#search_term = input(\"Enter the header you would like to search for\")\n",
    "\n",
    "search_with_toggle(base_directory)\n",
    "\n",
    "#results = search_notebooks_for_headers(base_directory, search_term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de18205-90fe-4386-a5dc-ea9f62ec3d20",
   "metadata": {},
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "\n",
    "###\n",
    "def search_with_toggle(base_dir):\n",
    "    #directory_searched = input(\"Enter the directory to be searched with path starting from home directory\")\n",
    "    search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "    case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    # Print results\n",
    "    for notebook, headers in results.items():\n",
    "        print(f\"Notebook: {notebook}\")\n",
    "        for header in headers:\n",
    "            print(f\"  Header: {header}\")\n",
    "###\n",
    "# Example usage\n",
    "#base_directory = \"sabbat\"  # Replace with the path to your base directory\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "#search_term = \"lists\"  # Replace with the phrase you want to search for\n",
    "#search_term = input(\"Enter the header you would like to search for\")\n",
    "\n",
    "search_with_toggle(base_directory)\n",
    "\n",
    "#results = search_notebooks_for_headers(base_directory, search_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74ed5b-8365-4512-b9de-de5828821e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sabbat_path = os.path.join(os.path.expanduser('~'), 'sabbat')\n",
    "sys.path.append(sabbat_path)\n",
    "import my_fun\n",
    "my_fun.search_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db556b5e-5fc1-4722-ae94-f2f078f192e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "def search_with_toggle(base_dir):\n",
    "    while True:\n",
    "        directory_searched= input(\"Directory to be searched: \")\n",
    "        search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "        case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "        results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "        # Print results\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "\n",
    "        another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "        if another_search != \"yes\":\n",
    "            print(\"Exiting the search tool.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "# Example usage\n",
    "#base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "base_directory = os.path.expanduser(\"~/{directory searched}\")\n",
    "search_with_toggle(base_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d78a4a-5f03-4b35-823c-648624d934ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nbformat\n",
    "\n",
    "def search_notebook_headers_with_prompt(directory=\".\"):\n",
    "    while True:\n",
    "        search_term = input(\"Enter the search term: \")\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".ipynb\"):\n",
    "                    notebook_path = os.path.join(root, file)\n",
    "                    with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        try:\n",
    "                            notebook = nbformat.read(f, as_version=4)\n",
    "                            for cell in notebook.cells:\n",
    "                                if cell.cell_type == \"markdown\":\n",
    "                                    for line in cell.source.splitlines():\n",
    "                                        if line.startswith(\"#\") and search_term in line:\n",
    "                                            print(f\"Notebook: {notebook_path}\")\n",
    "                                            print(f\"Header: {line}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reading {notebook_path}: {e}\")\n",
    "        \n",
    "        another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "        if another_search != \"yes\":\n",
    "            print(\"Exiting the search tool.\")\n",
    "            break\n",
    "search_notebook_headers_with_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a81c05-24a9-49a5-8ee3-be255c47f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    \"\"\"\n",
    "    Search all Jupyter notebooks in the given base directory and its subdirectories\n",
    "    for a specific phrase in markdown headers.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory to search.\n",
    "        search_phrase (str): The phrase to search for in markdown headers.\n",
    "        case_sensitive (bool): Whether the search should be case-sensitive.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are notebook file paths and values are lists of matching headers.\n",
    "    \"\"\"\n",
    "    matching_headers = {}\n",
    "\n",
    "    # Use glob to find all Jupyter notebooks recursively\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        # Combine the source lines into a single string\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        # Use regex to find headers (lines starting with #)\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        # Check if the search phrase is in any of the headers\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "def search_with_toggle(base_dir):\n",
    "    while True:\n",
    "        search_phrase = input(\"Enter the header you would like to search for: \")\n",
    "        case_sensitive = input(\"Should the search be case sensitive? (y/n): \").strip().lower() == 'y'\n",
    "\n",
    "        results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "        # Print results\n",
    "        for notebook, headers in results.items():\n",
    "            print(f\"Notebook: {notebook}\")\n",
    "            for header in headers:\n",
    "                print(f\"  Header: {header}\")\n",
    "\n",
    "        another_search = input(\"Do you want to perform another search? (yes/no): \").strip().lower()\n",
    "        if another_search != \"yes\":\n",
    "            print(\"Exiting the search tool.\")\n",
    "            break\n",
    "\n",
    "# Example usage\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "search_with_toggle(base_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65410469-abf3-4272-b0aa-8b503cc325a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated: /home/rebelford/sabbat/search_results.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/rebelford/sabbat/search_results.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "'''def generate_html_with_links(base_dir, search_phrase, case_sensitive=True):\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    html_content = \"\"\"<html>\n",
    "<head>\n",
    "    <title>Search Results</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Search Results</h1>\n",
    "\"\"\"\n",
    "\n",
    "    for notebook, headers in results.items():\n",
    "        relative_path = os.path.relpath(notebook, base_dir)\n",
    "        sharable_link = f\"./{relative_path}\"\n",
    "        html_content += f\"<h2><a href=\\\"{sharable_link}\\\">{relative_path}</a></h2>\\n\"\n",
    "        html_content += \"<ul>\\n\"\n",
    "        for header in headers:\n",
    "            html_content += f\"    <li>{header}</li>\\n\"\n",
    "        html_content += \"</ul>\\n\"\n",
    "\n",
    "    html_content += \"\"\"</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    output_file = os.path.join(base_dir, \"search_results.html\")\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"HTML file generated: {output_file}\")\n",
    "    return output_file'''\n",
    "\n",
    "def generate_html_with_links(base_dir, search_phrase, case_sensitive=True):\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "\n",
    "    html_content = \"\"\"<html>\n",
    "<head>\n",
    "    <title>Search Results</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Search Results</h1>\n",
    "\"\"\"\n",
    "\n",
    "    for notebook, headers in results.items():\n",
    "        relative_path = os.path.relpath(notebook, base_dir)\n",
    "        sharable_link = f\"./{relative_path}\"\n",
    "        # Replace 'files' with 'lab/tree' in the URL\n",
    "        sharable_link = sharable_link.replace('files', 'lab/tree')\n",
    "        html_content += f\"<h2><a href=\\\"{sharable_link}\\\">{relative_path}</a></h2>\\n\"\n",
    "        html_content += \"<ul>\\n\"\n",
    "        for header in headers:\n",
    "            html_content += f\"    <li>{header}</li>\\n\"\n",
    "        html_content += \"</ul>\\n\"\n",
    "\n",
    "    html_content += \"\"\"</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    output_file = os.path.join(base_dir, \"search_results.html\")\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"HTML file generated: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "base_directory = os.path.expanduser(\"~/sabbat\")\n",
    "search_term = \"lists\"\n",
    "generate_html_with_links(base_directory, search_term, case_sensitive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f9ab74-a5fb-40e7-a3f6-e817825d6674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated: /home/rebelford/sabbat/search_results_3.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_3.html\n",
      "HTML file generated: /home/rebelford/sabbat/search_results_4.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_4.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "\n",
    "def generate_html_with_links(base_dir, search_phrase, base_url=\"http://localhost:8888\", case_sensitive=True):\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "    \n",
    "    html_content = \"\"\"<html>\n",
    "    <head>\n",
    "        <title>Search Results</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Search Results</h1>\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_notebooks = set()  # To avoid duplicates\n",
    "\n",
    "    for notebook, headers in results.items():\n",
    "        if notebook in processed_notebooks:\n",
    "            continue\n",
    "        processed_notebooks.add(notebook)\n",
    "    \n",
    "        relative_path = os.path.relpath(notebook, base_dir)\n",
    "        sharable_link = f\"{base_url}/lab/tree/{relative_path}\"\n",
    "        \n",
    "        html_content += f\"<h2>Notebook: {notebook}</h2>\\n\"\n",
    "        html_content += f\"<p>Link: <a href=\\\"{sharable_link}\\\">{sharable_link}</a></p>\\n\"\n",
    "        html_content += \"<ul>\\n\"\n",
    "        for header in headers:\n",
    "            html_content += f\"    <li>{header}</li>\\n\"\n",
    "        html_content += \"</ul>\\n\"\n",
    "    \n",
    "    html_content += \"\"\"</body>\n",
    "    </html>\"\"\"\n",
    "    \n",
    "    # Append an integer to the filename to avoid overwriting\n",
    "    counter = 1\n",
    "    output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "\n",
    "\n",
    "    while os.path.exists(output_file):\n",
    "        counter += 1\n",
    "        output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"HTML file generated: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def main(base_directory, search_term, case_sensitive=True):\n",
    "    html_file = generate_html_with_links(base_directory, search_term, case_sensitive=case_sensitive)\n",
    "    print(f\"Search results saved to: {html_file}\")\n",
    "\n",
    "# In your notebook, you can then run:\n",
    "base_directory = \"/home/rebelford/sabbat/\"\n",
    "search_term = \"heap\"\n",
    "main(base_directory, search_term)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(base_directory, search_term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65aef7f3-16dd-46ff-95fc-3845d0b12f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML file generated: /home/rebelford/sabbat/search_results_5.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_5.html\n",
      "HTML file generated: /home/rebelford/sabbat/search_results_6.html\n",
      "Search results saved to: /home/rebelford/sabbat/search_results_6.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def search_notebooks_for_headers(base_dir, search_phrase, case_sensitive=True):\n",
    "    matching_headers = {}\n",
    "    notebook_files = glob.glob(os.path.join(base_dir, '**', '*.ipynb'), recursive=True)\n",
    "\n",
    "    for notebook in notebook_files:\n",
    "        with open(notebook, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                notebook_content = json.load(f)\n",
    "                for cell in notebook_content.get('cells', []):\n",
    "                    if cell.get('cell_type') == 'markdown':\n",
    "                        markdown_content = ''.join(cell.get('source', []))\n",
    "                        headers = re.findall(r'^(#+\\s.*)', markdown_content, re.MULTILINE)\n",
    "                        if case_sensitive:\n",
    "                            matching = [header for header in headers if search_phrase in header]\n",
    "                        else:\n",
    "                            matching = [header for header in headers if search_phrase.lower() in header.lower()]\n",
    "                        if matching:\n",
    "                            if notebook not in matching_headers:\n",
    "                                matching_headers[notebook] = []\n",
    "                            matching_headers[notebook].extend(matching)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error reading {notebook}. Skipping.\")\n",
    "\n",
    "    return matching_headers\n",
    "#\n",
    "\n",
    "def generate_html_with_links(base_dir, search_phrase, base_url=\"http://localhost:8888\", case_sensitive=True):\n",
    "    results = search_notebooks_for_headers(base_dir, search_phrase, case_sensitive)\n",
    "    \n",
    "    html_content = \"\"\"<html>\n",
    "    <head>\n",
    "        <title>Search Results</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Search Results</h1>\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_notebooks = set()  # To avoid duplicates\n",
    "    \n",
    "    for notebook, headers in results.items():\n",
    "        if notebook in processed_notebooks:\n",
    "            continue\n",
    "        processed_notebooks.add(notebook)\n",
    "        \n",
    "        relative_path = os.path.relpath(notebook, os.path.dirname(os.path.dirname(base_dir)))\n",
    "        sharable_link = f\"{base_url}/lab/tree/{relative_path}\"\n",
    "        html_content += f\"<h2><a href=\\\"{sharable_link}\\\">{relative_path}</a></h2>\\n\"\n",
    "        html_content += \"<ul>\\n\"\n",
    "        for header in headers:\n",
    "            html_content += f\"    <li>{header}</li>\\n\"\n",
    "        html_content += \"</ul>\\n\"\n",
    "\n",
    "    html_content += \"\"\"</body>\n",
    "    </html>\"\"\"\n",
    "\n",
    "    # Append an integer to the filename to avoid overwriting\n",
    "    counter = 1\n",
    "    output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "    while os.path.exists(output_file):\n",
    "        counter += 1\n",
    "        output_file = os.path.join(base_dir, f\"search_results_{counter}.html\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_content)\n",
    "\n",
    "    print(f\"HTML file generated: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def main(base_directory, search_term, case_sensitive=True):\n",
    "    html_file = generate_html_with_links(base_directory, search_term, case_sensitive=case_sensitive)\n",
    "    print(f\"Search results saved to: {html_file}\")\n",
    "\n",
    "# In your notebook, you can then run:\n",
    "base_directory = \"/home/rebelford/sabbat/\"\n",
    "search_term = \"heap\"\n",
    "main(base_directory, search_term)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(base_directory, search_term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b07576-63a3-4e64-9d71-e29304fde843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f17d1-f05a-4583-8efa-af371a3d2271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
